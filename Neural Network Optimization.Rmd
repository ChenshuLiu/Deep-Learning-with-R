---
title: "Deep Learning with R - Regularization"
author: "Chenshu Liu"
date: "April 2022"
output:
  pdf_document:
  html_document: default
---

\section{Data \& Library}
```{r}
library(readr)
library(keras)

setwd("~/Documents/Programming/R/Deep Learning with R/Datasets")
data.set <- read_csv("RegressionData.csv",
                     col_names = FALSE)
```
\section{Data Preprocessing}
\subsection{General Preprocessing}
```{r}
# transform dataframe to matrix
data.set <- as.matrix(data.set)
# remove column names
dimnames(data.set) <- NULL

# train test split
set.seed(123)
index <- sample(2,
                nrow(data.set),
                replace = TRUE,
                prob = c(0.8, 0.2))

x_train <- data.set[index == 1, 1:10]
x_test <- data.set[index == 2, 1:10]
y_train <- data.set[index == 1, 11]
y_test <- data.set[index == 2, 11]
```
\subsection{Normalization}
```{r}
# normalizing data
mean.train <- apply(x_train, 2, mean)
sd.train <- apply(x_train, 2, sd)
x_train <- scale(x_train)
# use the normalizing parameters from training set to normalize testing set
x_test <- scale(x_test,
                center = mean.train,
                scale = sd.train)
```
\section{Modeling}
```{r}
# creating the model
model <- keras_model_sequential() %>%
  layer_dense(units = 25,
              activation = "relu",
              input_shape = c(10)) %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 25,
              activation = "relu") %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 25,
              activation = "relu") %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 1)

model %>% summary()

# compile the model
model %>% compile(
  # the metric for propagation
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  # not for propagation, but for user feedback
  # letting us know the model's performance
  metrics = c("mean_absolute_error"))

# fitting the data
model_history <- model %>%
  fit(x_train,
      y_train,
      epoch = 50,
      batch_size = 32,
      validation_split = 0.1,
      callbacks = c(callback_early_stopping(monitor = "val_mean_absolute_error",
                                            patience = 5)),
      verbose = 2)

plot(model_history)

# testing the model
c(loss, mae) %<-% (model %>% evaluate(x_test, y_test, verbose = 0))
paste0("Mean Absolute Error on test set is:", mae)
```