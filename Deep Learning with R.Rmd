---
title: "Deep Learning with R"
author: "Chenshu Liu"
date: "April 2022"
output:
  pdf_document:
    toc: true
    toc_depth: 2
  html_document: default
---

```{r, echo=FALSE}
setwd("~/Documents/Programming/R/Deep Learning with R")
```

\newpage
\section{DL 01 Regression as a first step in deep learning}
\subsection{Prediction from linear regression}
```{r}
# Scenario: predicting sales performance
sales <- c(3, 4, 2, 4, 5, 6, 3, 9, 1, 12)
```
In the simplest way possible, we can simple find the mean of all the observations, and use the mean as our prediction for future sales performances
$$Performance = \frac{\Sigma_{i=1}^n x_i}{n}$$
```{r}
mean.sales <- mean(sales)
mean.sales
```
\subsection{How to measure error in prediction}
However, using only the mean as future prediction is not close to accurate, we are bound to make errors. Thus, to measure the magnitude of the error we are making using the mean, we introduce the concept of *sum of squared errors (SSE)*:
$$SSE = \Sigma_{i = 1}^n (x_i - \bar{X})^2$$
Where $\bar{X}$ is the mean of the observations. 

**NOTE:** There the differences are squared because there can be positive and negative numbers in the differences, and summing positive and negative differences together will make 0. Thus, we need to **square** the differences to make them significant.
```{r}
SSE = sum((sales - mean.sales)^2)
SSE
```
However, the measurement of deviation from actual observations has some limitations:
\begin{enumerate}
  \item In the calculation of SSE, we summed all the differences together, which means the sample size plays a role in the calculation of the deviation. Thus, in order to rule out the effect of sample size on SSE, we introduce the idea of **variance**: $var = \frac{\Sigma_{i = 1}^n (x_i - \bar{X})^2}{n - 1}$, where $n - 1$ is the degrees of freedom. Now, the standard deviation is a square-root version of the measurement of deviation, which makes more sense.
  \item Because the differences are squared, it is hard for us to interpret the deviation, thus, we further introduce the idea of *standard deviation*: $s = \sqrt{\frac{\Sigma_{i = 1}^n (x_i - \bar{X})^2}{n - 1}}$
\end{enumerate}
Both the variance and standard deviation describes how bad the model's prediction is
```{r}
variance <- (sum((sales - mean.sales)^2))/(length(sales) - 1)
variance
# base R function
var(sales)
standard.deviation <- sqrt((sum((sales - mean.sales)^2))/(length(sales) - 1))
standard.deviation
# base R function
sd(sales)
```
So, predictions are bound to have errors:
\begin{align*}
  y_i &= \bar{X} + \epsilon_i\\
  target &= model + error
\end{align*}
**Take away:** After learning about how to measure the accuracy of a prediction model, we now need to know how to optimize the model and letting it to generate more accurate predictions. The task of optimizing the model that minimizes prediction error is the in the scope of Deep Learning!
\subsection{How to potentially reduce prediction error}
Assume that we have a base-line linear regression model that has a SSE we call *sst* (unsystematic variance), if we tune the slope and intercept of the base-line linear regression model, it has a new SSE we call *ssm* (systematic variance). Thus, in order to **measure the improvement in prediction accuracy brought by tuning the parameters in the model**, we introduce the measurement of R-squared: 
$$R^2 = \frac{ssm}{sst}$$
$R^2$ describes the amount of variance that can be described by the new, improved model, with respect to the base-line model.

\subsection{Preview on next section}
**Thought question:** we know that tuning the parameters in the model can lead to improvement in the prediction performance, but how can we find the optimal parameter that can minimize the prediction error (**core** goal in deep learning). This is what we will be covering in the next section

Reference video: https://www.youtube.com/watch?v=0F2bBZiirlg&list=PLH5_eZVldmtUCZWp-eL0lVL7SA6qyDIf9&index=1 

\newpage
\section{DL 02 Linear regression as a Simple Learner "SL"}
\subsection{Related functions/calculations in prediction}
\subsubsection{Prediction function}
From last section, we introduced that predictions can be made with a linear function in the form of:
$$\hat{y_i}(x_i) = \beta_0 + \beta_1x_i$$
Where $\hat{y}$ is the predicted value based on the prediction function
\subsubsection{Loss function}
Loss function is used to measure the amount of error in **one of** our predictions using the model:
$$L(x_i) = [\hat{y_i}(x_i) - y_i]^2$$
The loss function is just the SSE that we introduced in the last section, where we take the square of the differences between observed and predicted value, at the ith position (because there are many observations and predictions)
\subsubsection{Cost function}
The cost function is a little from the loss function because the cost function is calculated from the persepective of the overall prediction, instead of each individual prediction's deviation (calculated by loss function):
\begin{align*}
  C(\beta_0, \beta_1) &= \frac{1}{n}\Sigma_{i = 1}^n L\\
                      &= \frac{1}{n}\Sigma_{i = 1}^n [\hat{y_i}(x_i) - y_i]^2\\
                      &= \frac{1}{n}\Sigma_{i = 1}^n [\beta_0 + \beta_1x_i - y_i]^2
\end{align*}

\subsection{How to find the optimial parameters}
Say we find a cost function that is:
\begin{align*}
  C &= \frac{1}{5}\times{[\beta_0 + \beta_1(1.3) - 0.7]^2 + \dots + [\beta_0 + \beta_1(3.3) - 3.5]^2}\\
  &= 6.55 - 4.68\beta_0 + \beta_0^2 - 13.132\beta_1 + 5.08\beta_0\beta_1 + 7.002\beta_1^2
\end{align*}
We can see that the cost function is composed of the two parameters $\beta_0$ and $\beta_1$, and we also know that we want to minimize the cost function. So, our goal now is to find optimal values of $\beta_0$ and $\beta_1$ so that the cost function is at its minimum. The way to achieve so, its through using **partial derivatives**

\begin{align}
  \frac{\partial C}{\partial \beta_0} &= 2\beta_0 + 5.08\beta_1 - 4.68\\
  \frac{\partial C}{\partial \beta_1} &= 5.08\beta_0 + 14.004\beta_1 - 13.132
\end{align}
By solving (1) and (2), we can obtain the following augmented matrix for the linear system:
$$\begin{bmatrix}
2 & 5.08 & 4.68 \\
5.08 & 14.004 & 13.132 \\
\end{bmatrix}$$
Then, we can reduce the augmented matrix which give us the final values for $\beta_0 = -0.532267$ and $\beta_1 = 1.13081$

\subsection{Gradient descent}
The case above is a two dimensional (having to variables), which is rather simple. However, in real-life scenarios, we often have many parameters and we still need to find the set of parameters that minimizes the cost function, so we ought to find a more generalized way to find optimal parameters, so we introduce the idea of **gradient descent**
\begin{enumerate}
  \item Randomly choose a point in space and find the derivative (i.e. slope) of the cost function at that particular point: $slope_x$
  \item Define a learning rate (LR), which is a predefined value for gradient descent
  \item Calculate step: $x_{new} = x - LR\times slope_x$
  \item Repeat the same process from step1-3 for $x_{new}$
\end{enumerate}

Reference video: https://www.youtube.com/watch?v=FrceOv_oJac&list=PLH5_eZVldmtUCZWp-eL0lVL7SA6qyDIf9&index=2 

\newpage
\section{DL 03 Linear regression as a Shallow Neural Network "SNN"}
\subsection{Multiple linear regression in R}
```{r}
df <- read.csv("MultipleLinearRegression.csv")
df
```
After preliminary view of the data, we can see that there are three independent variables $x_1, x_2, x_3$, so we are dealing with a multiple linear regression:
$$\beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 \approx y$$
Now, there are four parameters (i.e. $\beta_0, \beta_1, \beta_2, \beta_3$) that we need to tune, in order to optimize prediction, so we have the loss function for the four parameters:
$$L^{(i)}(\beta_0, \beta_1, \beta_2, \beta_3) = (\beta_0 + \beta_1x_1^{(i)} + \beta_2x_2^{(i)} + \beta_3x_3^{(i)} - y^{(i)})^2$$
```{r}
# multiple linear regression
mlr <- lm(y ~., data = df)
summary(mlr)
```

\subsection{Single layer neural network}
Based on the multiple linear regression we conducted in last subsection, we are actually getting into neural network layers. The multiple linear regression itself can be considered as a single layer network (Figure 1: Single Layer Neural Network), where the inputs are taken into hidden layers and multiplied with the weights (the parameters), and then output the prediction in the output layer

![Single Layer Neural Network](Hand_written_notes/single layer NN.jpeg)

Now, here's when things get interesting:
\begin{enumerate}
  \item We can use **forward propagation** to find output prediction (i.e. feeding in input values, and calculate for output)
  \item We can also use **backward propagation** to better tune the parameters (i.e. using the predicted values, we can go back to tune the parameters and allow for better prediction performance)
\end{enumerate}

Reference video: https://www.youtube.com/watch?v=ZX4YSidnQaI&list=PLH5_eZVldmtUCZWp-eL0lVL7SA6qyDIf9&index=6

\newpage
\section{DL 04 Logistic regression as a Neural Network}
\subsection{Why do we need logistic regression?}
So far, we have looked at ways which we can find predictions about numerical outcome, but there are real-life cases where the prediction of binary outcomes is needed. It's where logistic regression comes into play. Logistic regression is specifically designed to deal with prediction of binary outcomes

\subsection{Mechanism of logistic regression}
Logistic regression is similar to simple linear regression in every way except for the outcome variable. Simple linear regression produces numerical outcomes while logistic regression produces binary outcome. Because the rest of the algorithm is just the same as simple linear regression, logistic regression also has parameters $\beta_0, \beta_1, \dots, \beta_n$, and the way in which we can achieve the best prediction model is to find values for the parameters that can minimize the cost function

For logistic regression, the solution is a sigmoidal function:
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$
Where z in the expression can be expressed as $z(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_4x_4$. One of the key property of sigmoidal function is that its solution is always between 0 and 1, and we can define a threshold (i.e. cutoff) to determine which side the outcome belongs to (i.e. 0 or 1), which fits the purpose of deriving binary outcomes

Reference video: https://www.youtube.com/watch?v=7TjN1kuJidA&list=PLH5_eZVldmtUCZWp-eL0lVL7SA6qyDIf9&index=7 

\newpage
\section{DL 05 Deep Neural Network in R - Example}
\subsection{Libaries \& Data}
```{r, message = FALSE, warning = FALSE}
# import spreadsheet files
library(readr)
# deep learning package
library(keras)
# dynamic interactive tables
library(DT)

data <- read_csv("SimulatedBinaryClassificationDataset.csv",
                 col_names = TRUE)
summary(data)
```

\subsection{Data preprocessing}
Because deep learning is achieved through manipulation of matrices, we cannot pass in dataframe format data, so we need to change the format of the data to matrix during preprocessing
```{r}
# data.frame --> matrix
data  <- as.matrix(data)
# remove the row and col names, leaving only numerical values
dimnames(data) = NULL
mode(data)
```
Also, deep learning involves separate training and testing phases in order optimize the model's performance, so we need tp prepare for training and testing sets during preprocessing
```{r}
# train and test split index
set.seed(123)
index <- sample(2,
                nrow(data),
                replace = TRUE,
                prob = c(0.9, 0.1))
table(index)

# data splitting
x_train <- data[index == 1, 1:10]
x_test <- data[index == 2, 1:10]
y_test_actual <- data[index == 2, 11]
```
In cases where the target variable has multiple categories, our deep learning network wouldn't be able to process raw categorical information, so we need to convert the categories into numerical matrix format. One common way of encoding the target variable is through **one-hot encoding**:

Simply put, one-hot encoding would expand the column vector of categories and make each category an independent column. If the original label fits into a category, then the column with the category will be labeled 1, otherwise 0
```{r}
# use teh to_categorical function in keras package for one-hot encoding
y_train <- to_categorical(data[index == 1, 11])
y_test <- to_categorical(data[index == 2, 11])
```

\subsection{Creating a simple model}
```{r}
model <- keras_model_sequential()

model %>%
  # layer_dense means a densely connected layer
  layer_dense(name = "DeepLayer1",
              units = 10, # hyperparameter: the number of nodes
              activation = "relu",
              # the first layer need to have specification about the input dimension
              input_shape = c(10)) %>%
  layer_dense(name = "DeepLayer2",
              units = 10,
              activation = "relu") %>%
  layer_dense(name = "OutputLayer",
              units = 2,
              # softmax function will provide probabilities of the nodes
              activation = "softmax")

summary(model)
```
According to the summary table of the deep learning model, we can see that the number of parameters is very large:
\begin{enumerate}
  \item DeepLayer 1 has 110 parameters after passing the 10 input values, this is because neural network connects all the input with the nodes in the hidden layer which results in $10 \times 10 = 100$, and there is a bias term associating with every input, so the total number of parameters is $10 + 10\times 10 = 110$
  \item DeepLayer 2 also has 110 parameters, which is from the same reason as DeepLayer 1
  \item OutputLayer has 22 parameters: $10 \times 2 + 2 = 22$
  \item Thus, the total number of parameters in our two hidden layer network is already so large: $110 + 110 + 22 = 242$, so we need to tune 242 parameters for the model through forward/backward propagation, which can make the performance so much better 
\end{enumerate}

\subsection{Compile the model}
```{r}
model %>% compile(
  # another way to calculate loss, besides mean-squared-error
  loss = "categorical_crossentropy", 
  # a special way of gradient descent
  optimizer = "adam",
  # measurement of model performance - using accuracy to measure
  metrics = c("accuracy")) 
```

\subsection{Fitting the data}
```{r}
history <- model %>%
  fit(x_train,
      y_train,
      # number of full forward & backward propagation
      # (i.e. run 10 times back and forth of all samples)
      epoch = 10, 
      # instead of propagating the whole dataset at one go, use smaller batches
      batch_size = 256, 
      # splitting the training set to test itself during training
      validation_split = 0.1, 
      verbose = 2)
```
Arguments for fitting the model (hyperparameters):
\begin{enumerate}
  \item epoch: one forward pass and one backward pass of \textbf{all} the training samples
  \item batch size: the number of training examples in one forward/backward pass, usually, for better memory performance, we use values that are $2^n$
\end{enumerate}
```{r, message = F}
# plot the training history
plot(history)
```


\subsection{Model evaluation}
Be aware of the new update in tensorFlow 2.8.0: https://keras.rstudio.com/reference/predict_proba.html 
```{r}
model %>%
  evaluate(x_test,
           # NOTE: here we are still using the one-hot encoded y_test
           y_test)

# form predictions
pred <- model %>%
  predict(x_test) %>%
  k_argmax()
# reference for converting tensor to R data types
# https://torch.mlverse.org/technical/tensors/
pred <- as.array(pred)
table(Predicted = pred,
      # NOTE: for confusion matrix, we are using the original y_test_actual, not encoded
      Actual = y_test_actual)
```






















